name: Disaster Recovery & Restore
on:
  workflow_dispatch:
    inputs:
      restore_type:
        description: 'Type of restore operation'
        required: true
        type: choice
        options:
        - 'full-restore'
        - 'database-only'
        - 'files-only'
        - 'test-restore'
      backup_id:
        description: 'Backup ID to restore from (YYYYMMDD_HHMMSS format)'
        required: true
        type: string
      target_site:
        description: 'Target site name for restore'
        required: false
        type: string
      confirm_restore:
        description: 'Type "CONFIRM" to proceed with restore'
        required: true
        type: string

env:
  AWS_REGION: us-east-1
  TERRAFORM_DIR: iac/aws/ec2/terraform

jobs:
  validate-inputs:
    name: Validate Restore Inputs
    runs-on: ubuntu-latest
    outputs:
      validation_passed: ${{ steps.validate.outputs.passed }}
      
    steps:
    - name: Validate inputs
      id: validate
      run: |
        CONFIRM="${{ github.event.inputs.confirm_restore }}"
        BACKUP_ID="${{ github.event.inputs.backup_id }}"
        
        echo "Validating restore inputs..."
        
        # Check confirmation
        if [ "$CONFIRM" != "CONFIRM" ]; then
          echo "❌ Restore not confirmed. Please type 'CONFIRM' to proceed."
          exit 1
        fi
        
        # Validate backup ID format
        if [[ ! "$BACKUP_ID" =~ ^[0-9]{8}_[0-9]{6}$ ]]; then
          echo "❌ Invalid backup ID format. Expected: YYYYMMDD_HHMMSS"
          echo "Example: 20240315_143022"
          exit 1
        fi
        
        echo "✅ Input validation passed"
        echo "passed=true" >> $GITHUB_OUTPUT
        
  restore:
    name: Execute Disaster Recovery
    runs-on: ubuntu-latest
    needs: validate-inputs
    if: needs.validate-inputs.outputs.validation_passed == 'true'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
        
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
        terraform_wrapper: false
        
    - name: Get infrastructure information
      id: get-info
      working-directory: ${{ env.TERRAFORM_DIR }}
      run: |
        terraform init -backend-config=backend-config.tf
        INSTANCE_ID=$(terraform output -raw instance_id)
        BACKUP_BUCKET=$(terraform output -raw backup_bucket_name)
        echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
        echo "backup_bucket=$BACKUP_BUCKET" >> $GITHUB_OUTPUT
        
    - name: Verify backup exists
      run: |
        BACKUP_BUCKET="${{ steps.get-info.outputs.backup_bucket }}"
        BACKUP_ID="${{ github.event.inputs.backup_id }}"
        BACKUP_FILE="erpnext_backup_$BACKUP_ID.tar.gz"
        
        echo "Verifying backup exists in S3..."
        echo "Backup bucket: $BACKUP_BUCKET"
        echo "Backup file: $BACKUP_FILE"
        
        if aws s3 ls "s3://$BACKUP_BUCKET/backups/$BACKUP_FILE" > /dev/null; then
          echo "✅ Backup file found in S3"
          
          # Get backup metadata
          METADATA_FILE="backup_metadata_$BACKUP_ID.json"
          if aws s3 cp "s3://$BACKUP_BUCKET/metadata/$METADATA_FILE" /tmp/metadata.json 2>/dev/null; then
            echo "✅ Backup metadata found"
            echo "Backup metadata:"
            cat /tmp/metadata.json | jq .
          else
            echo "⚠️ Backup metadata not found, proceeding anyway"
          fi
        else
          echo "❌ Backup file not found in S3"
          echo "Available backups:"
          aws s3 ls "s3://$BACKUP_BUCKET/backups/" | grep erpnext_backup
          exit 1
        fi
        
    - name: Prepare restore script
      run: |
        cat > restore-erpnext.sh << 'EOF'
        #!/bin/bash
        set -e
        
        # Configuration
        RESTORE_TYPE="${{ github.event.inputs.restore_type }}"
        BACKUP_ID="${{ github.event.inputs.backup_id }}"
        TARGET_SITE="${{ github.event.inputs.target_site }}"
        BACKUP_BUCKET="${{ steps.get-info.outputs.backup_bucket }}"
        BACKUP_FILE="erpnext_backup_$BACKUP_ID.tar.gz"
        RESTORE_DIR="/tmp/restore_$BACKUP_ID"
        
        echo "=== Disaster Recovery Started ==="
        echo "Restore Type: $RESTORE_TYPE"
        echo "Backup ID: $BACKUP_ID"
        echo "Target Site: ${TARGET_SITE:-auto-detect}"
        echo "Timestamp: $(date)"
        
        # Create restore directory
        mkdir -p $RESTORE_DIR
        cd $RESTORE_DIR
        
        # Download backup from S3
        echo "Downloading backup from S3..."
        aws s3 cp "s3://$BACKUP_BUCKET/backups/$BACKUP_FILE" .
        
        # Extract backup
        echo "Extracting backup..."
        tar -xzf "$BACKUP_FILE"
        
        BACKUP_EXTRACT_DIR="backup_$BACKUP_ID"
        if [ ! -d "$BACKUP_EXTRACT_DIR" ]; then
          echo "❌ Backup extraction failed or unexpected structure"
          ls -la
          exit 1
        fi
        
        cd "$BACKUP_EXTRACT_DIR"
        echo "Backup contents:"
        ls -la
        
        # Check if ERPNext is running
        cd /opt/erpnext/frappe_docker
        if ! docker compose --project-name erpnext -f ~/gitops/docker-compose.yml ps | grep -q "Up"; then
          echo "⚠️ ERPNext containers are not running. Starting them first..."
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml up -d
          sleep 30
        fi
        
        # Function to restore database
        restore_database() {
          local site=$1
          local db_file=$2
          
          echo "Restoring database for site: $site"
          echo "Database file: $db_file"
          
          if [ ! -f "$db_file" ]; then
            echo "❌ Database backup file not found: $db_file"
            return 1
          fi
          
          # Copy database file to container
          docker cp "$db_file" $(docker compose --project-name erpnext -f ~/gitops/docker-compose.yml ps -q backend):/tmp/
          
          # Get database name from site config
          DB_NAME=$(docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
            python -c "import json; print(json.load(open('sites/$site/site_config.json'))['db_name'])" 2>/dev/null || echo "$site")
          
          # Drop existing database if exists
          if [ "$RESTORE_TYPE" != "test-restore" ]; then
            echo "Dropping existing database: $DB_NAME"
            docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T db \
              mysql -u root -p${DB_PASSWORD:-admin} -e "DROP DATABASE IF EXISTS \`$DB_NAME\`;"
          fi
          
          # Create new database
          echo "Creating database: $DB_NAME"
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T db \
            mysql -u root -p${DB_PASSWORD:-admin} -e "CREATE DATABASE \`$DB_NAME\` CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;"
          
          # Restore database
          echo "Restoring database contents..."
          DB_FILE_NAME=$(basename "$db_file")
          
          if [[ "$DB_FILE_NAME" == *.gz ]]; then
            docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
              bash -c "zcat /tmp/$DB_FILE_NAME | mysql -h db -u root -p${DB_PASSWORD:-admin} $DB_NAME"
          else
            docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
              bash -c "mysql -h db -u root -p${DB_PASSWORD:-admin} $DB_NAME < /tmp/$DB_FILE_NAME"
          fi
          
          echo "✅ Database restored successfully"
        }
        
        # Function to restore files
        restore_files() {
          local site=$1
          local files_backup=$2
          
          echo "Restoring files for site: $site"
          echo "Files backup: $files_backup"
          
          if [ ! -f "$files_backup" ]; then
            echo "❌ Files backup not found: $files_backup"
            return 1
          fi
          
          # Copy files backup to container
          docker cp "$files_backup" $(docker compose --project-name erpnext -f ~/gitops/docker-compose.yml ps -q backend):/tmp/
          
          # Create temporary extraction directory in container
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
            mkdir -p /tmp/files_restore
          
          # Extract files in container
          FILES_FILE_NAME=$(basename "$files_backup")
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
            bash -c "cd /tmp/files_restore && tar -xf /tmp/$FILES_FILE_NAME"
          
          # Stop backend services temporarily
          echo "Stopping backend services for file restore..."
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml stop backend frontend
          
          # Backup current files if not test restore
          if [ "$RESTORE_TYPE" != "test-restore" ]; then
            echo "Backing up current files..."
            docker compose --project-name erpnext -f ~/gitops/docker-compose.yml run --rm backend \
              bash -c "cd sites/$site && tar -czf /tmp/current_files_backup.tar.gz public private"
          fi
          
          # Restore files
          echo "Restoring files..."
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml run --rm backend \
            bash -c "cd /tmp/files_restore && cp -r * /home/frappe/frappe-bench/sites/$site/"
          
          # Fix permissions
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml run --rm backend \
            bash -c "chown -R frappe:frappe sites/$site/public sites/$site/private"
          
          # Start services
          echo "Starting backend services..."
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml start backend frontend
          
          echo "✅ Files restored successfully"
        }
        
        # Determine sites to restore
        cd "$RESTORE_DIR/$BACKUP_EXTRACT_DIR"
        
        if [ ! -z "$TARGET_SITE" ]; then
          SITES_TO_RESTORE="$TARGET_SITE"
        else
          # Auto-detect sites from backup
          SITES_TO_RESTORE=$(ls -d */ 2>/dev/null | grep -v system | sed 's|/||g' || echo "")
        fi
        
        echo "Sites to restore: $SITES_TO_RESTORE"
        
        if [ -z "$SITES_TO_RESTORE" ]; then
          echo "❌ No sites found to restore"
          exit 1
        fi
        
        # Perform restore for each site
        for site in $SITES_TO_RESTORE; do
          if [ -d "$site" ]; then
            echo "Processing site: $site"
            
            # Find backup files for this site
            DB_FILE=$(find "$site" -name "*database*.sql.gz" -o -name "*database*.sql" | head -1)
            FILES_FILE=$(find "$site" -name "*files*.tar" | head -1)
            
            echo "Database backup: ${DB_FILE:-not found}"
            echo "Files backup: ${FILES_FILE:-not found}"
            
            # Check if site exists in current ERPNext
            SITE_EXISTS=$(docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
              bash -c "ls sites/ | grep -c '^$site$'" 2>/dev/null || echo "0")
            
            if [ "$SITE_EXISTS" = "0" ] && [ "$RESTORE_TYPE" != "test-restore" ]; then
              echo "Site $site does not exist, creating it first..."
              
              # Create site with minimal configuration
              docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
                bench new-site $site \
                --mariadb-user-host-login-scope=% \
                --admin-password=temp_password \
                --db-root-password=${DB_PASSWORD:-admin}
            fi
            
            # Perform restore operations based on type
            if [ "$RESTORE_TYPE" = "full-restore" ]; then
              [ ! -z "$DB_FILE" ] && restore_database "$site" "$DB_FILE"
              [ ! -z "$FILES_FILE" ] && restore_files "$site" "$FILES_FILE"
            elif [ "$RESTORE_TYPE" = "database-only" ]; then
              [ ! -z "$DB_FILE" ] && restore_database "$site" "$DB_FILE"
            elif [ "$RESTORE_TYPE" = "files-only" ]; then
              [ ! -z "$FILES_FILE" ] && restore_files "$site" "$FILES_FILE"
            elif [ "$RESTORE_TYPE" = "test-restore" ]; then
              echo "Test restore - validating backup integrity only"
              [ ! -z "$DB_FILE" ] && echo "✅ Database backup file is present and readable"
              [ ! -z "$FILES_FILE" ] && echo "✅ Files backup is present and readable"
            fi
            
            # Restore site configuration if available
            if [ -f "$site/config_${site}_$BACKUP_ID.tar.gz" ]; then
              echo "Restoring site configuration..."
              docker cp "$site/config_${site}_$BACKUP_ID.tar.gz" \
                $(docker compose --project-name erpnext -f ~/gitops/docker-compose.yml ps -q backend):/tmp/
              
              docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
                bash -c "cd sites/$site && tar -xzf /tmp/config_${site}_$BACKUP_ID.tar.gz"
            fi
          else
            echo "⚠️ Site directory not found in backup: $site"
          fi
        done
        
        # Restore system configuration if present
        if [ -d "system" ]; then
          echo "Restoring system configuration..."
          
          if [ -f "system/common_site_config.json" ]; then
            docker cp "system/common_site_config.json" \
              $(docker compose --project-name erpnext -f ~/gitops/docker-compose.yml ps -q backend):/home/frappe/frappe-bench/sites/
          fi
        fi
        
        # Run post-restore operations
        if [ "$RESTORE_TYPE" != "test-restore" ]; then
          echo "Running post-restore operations..."
          
          for site in $SITES_TO_RESTORE; do
            echo "Running migrations for site: $site"
            docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
              bench --site $site migrate || echo "Migration failed for $site, continuing..."
            
            echo "Clearing cache for site: $site"
            docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
              bench --site $site clear-cache || echo "Cache clear failed for $site, continuing..."
          done
          
          # Restart all services
          echo "Restarting all services..."
          docker compose --project-name erpnext -f ~/gitops/docker-compose.yml restart
          
          # Wait for services to be ready
          echo "Waiting for services to be ready..."
          sleep 30
          
          # Test site accessibility
          for site in $SITES_TO_RESTORE; do
            echo "Testing site accessibility: $site"
            for i in {1..5}; do
              if docker compose --project-name erpnext -f ~/gitops/docker-compose.yml exec -T backend \
                bash -c "curl -f -s http://localhost:8000/api/method/ping -H 'Host: $site'" > /dev/null; then
                echo "✅ Site $site is accessible"
                break
              elif [ $i -eq 5 ]; then
                echo "⚠️ Site $site may not be fully ready yet"
              else
                echo "Waiting for site $site to be ready... (attempt $i/5)"
                sleep 10
              fi
            done
          done
        fi
        
        # Cleanup
        echo "Cleaning up temporary files..."
        rm -rf "$RESTORE_DIR"
        
        echo "=== Disaster Recovery Completed ==="
        echo "Restore Type: $RESTORE_TYPE"
        echo "Backup ID: $BACKUP_ID"
        echo "Sites Restored: $SITES_TO_RESTORE"
        echo "Completed at: $(date)"
        
        if [ "$RESTORE_TYPE" != "test-restore" ]; then
          echo ""
          echo "⚠️ IMPORTANT POST-RESTORE ACTIONS:"
          echo "1. Test all critical functionality"
          echo "2. Verify data integrity"
          echo "3. Update any environment-specific configurations"
          echo "4. Consider running a full backup after verification"
          echo "5. Update DNS/SSL if needed"
        fi
        EOF
        
        chmod +x restore-erpnext.sh
        
    - name: Execute restore via SSM
      run: |
        COMMAND_ID=$(aws ssm send-command \
          --instance-ids ${{ steps.get-info.outputs.instance_id }} \
          --document-name "AWS-RunShellScript" \
          --parameters commands="$(cat restore-erpnext.sh | base64 -w 0 | base64 -d)" \
          --timeout-seconds 3600 \
          --query 'Command.CommandId' \
          --output text)
          
        echo "Command ID: $COMMAND_ID"
        echo "command_id=$COMMAND_ID" >> $GITHUB_ENV
        
        # Wait for command to complete (longer timeout for restore operations)
        echo "Waiting for restore to complete..."
        aws ssm wait command-executed \
          --command-id $COMMAND_ID \
          --instance-id ${{ steps.get-info.outputs.instance_id }}
          
    - name: Get restore results
      id: restore-results
      run: |
        echo "=== Restore Results ==="
        OUTPUT=$(aws ssm get-command-invocation \
          --command-id ${{ env.command_id }} \
          --instance-id ${{ steps.get-info.outputs.instance_id }} \
          --query 'StandardOutputContent' \
          --output text)
        
        echo "$OUTPUT"
        
        echo "=== Error Output (if any) ==="
        ERROR_OUTPUT=$(aws ssm get-command-invocation \
          --command-id ${{ env.command_id }} \
          --instance-id ${{ steps.get-info.outputs.instance_id }} \
          --query 'StandardErrorContent' \
          --output text)
        
        echo "$ERROR_OUTPUT"
        
        # Check command status
        STATUS=$(aws ssm get-command-invocation \
          --command-id ${{ env.command_id }} \
          --instance-id ${{ steps.get-info.outputs.instance_id }} \
          --query 'Status' \
          --output text)
          
        echo "Command Status: $STATUS"
        echo "restore_status=$STATUS" >> $GITHUB_OUTPUT
        
        if [ "$STATUS" != "Success" ]; then
          echo "Restore operation failed!"
          exit 1
        fi
        
    - name: Post-restore verification
      if: github.event.inputs.restore_type != 'test-restore'
      run: |
        echo "=== Post-Restore Verification ==="
        
        # Wait a bit for services to stabilize
        sleep 60
        
        # Here you could add specific verification steps:
        # - Check site accessibility
        # - Verify specific data
        # - Run health checks
        
        echo "Restore verification completed"
        echo "Please manually verify:"
        echo "1. Site functionality"
        echo "2. Data integrity" 
        echo "3. User access"
        echo "4. Integrations"
        
    - name: Create restore summary
      if: always()
      run: |
        RESTORE_STATUS="${{ steps.restore-results.outputs.restore_status }}"
        
        cat >> $GITHUB_STEP_SUMMARY << EOF
        # 🔄 Disaster Recovery Summary
        
        ## Restore Operation
        - **Status**: $([ "$RESTORE_STATUS" = "Success" ] && echo "✅ Success" || echo "❌ Failed")
        - **Restore Type**: ${{ github.event.inputs.restore_type }}
        - **Backup ID**: ${{ github.event.inputs.backup_id }}
        - **Target Site**: ${{ github.event.inputs.target_site || 'Auto-detected' }}
        - **Executed At**: $(date -u)
        
        ## Operation Details
        - **Instance ID**: ${{ steps.get-info.outputs.instance_id }}
        - **Backup Source**: S3 bucket ${{ steps.get-info.outputs.backup_bucket }}
        - **Confirmation**: Provided by user
        
        ## Post-Restore Checklist
        $(if [ "${{ github.event.inputs.restore_type }}" != "test-restore" ]; then
          echo "- [ ] Verify site accessibility
        - [ ] Test critical functionality
        - [ ] Check data integrity
        - [ ] Verify user access
        - [ ] Test integrations
        - [ ] Update configurations if needed
        - [ ] Run full backup after verification
        - [ ] Update DNS/SSL if required"
        else
          echo "- [x] Backup integrity verified
        - [x] Test restore completed successfully"
        fi)
        
        ## Important Notes
        $(if [ "${{ github.event.inputs.restore_type }}" != "test-restore" ]; then
          echo "⚠️ **This was a live restore operation**
        - All data has been replaced with backup data
        - Verify everything is working correctly
        - Consider running a backup after verification"
        else
          echo "✅ **This was a test restore only**
        - No live data was affected
        - Backup integrity has been verified"
        fi)
        
        ## Next Steps
        1. Complete the post-restore checklist above
        2. Monitor system health for the next 24 hours
        3. Document any issues or unexpected behaviors
        4. Update disaster recovery procedures if needed
        EOF
